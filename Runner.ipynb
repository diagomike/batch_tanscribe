{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnW7Gf5brhVb"
      },
      "source": [
        "###### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Prrr23ptmOHR"
      },
      "outputs": [],
      "source": [
        "!apt-get install ffmpeg\n",
        "!pip install ffmpeg-python\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9OQeLX8MxxzT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ffmpeg # preprocess\n",
        "import torch # model download\n",
        "import whisper # model download\n",
        "import datetime # overlap removal\n",
        "import json #for loading from file Json->.srt\n",
        "# whisper mode dependancies\n",
        "from tqdm import tqdm\n",
        "\n",
        "from whisper.utils import get_writer #frin dict to .srt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuBg2RtYreiB"
      },
      "source": [
        "###### Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qulwO5y7m5qh"
      },
      "outputs": [],
      "source": [
        "def proccess_for_VAD(audio_path,VAD_temp_path,vad_threshold=0.4,chunk_threshold=3.0):\n",
        "    \"\"\"#recives Audio from audio_path splits by VAD trimming and padding and semgenting & everything...\n",
        "    #saves the segments VAD_temp_path, \n",
        "    # vad_treshold .srt parts split threshold\n",
        "    # chunk_threshold segment separation threshold\"\"\"\n",
        "\n",
        "    #?note this includes the extention// Just for memory\n",
        "    audio_name = audio_path.split('/')[-1].split('.')[0]+'.wav' #TODO maybe later split for name simplicity\n",
        "    print(\"Encoding audio for VAD...\",audio_name)\n",
        "    if not os.path.exists(VAD_temp_path):\n",
        "        os.mkdir(VAD_temp_path)\n",
        "    print(audio_path,f\"{VAD_temp_path}/{audio_name}\",\"VAD\")\n",
        "    ffmpeg.input(audio_path).output(\n",
        "        f\"{VAD_temp_path}/{audio_name}\",\n",
        "        ar=\"16000\",\n",
        "        ac=\"1\",\n",
        "        acodec=\"pcm_s16le\",\n",
        "        map_metadata=\"-1\",\n",
        "        fflags=\"+bitexact\",\n",
        "    ).overwrite_output().run(quiet=True)\n",
        "    \n",
        "    #? downlaod VAD model and the requrired utils\n",
        "    print(\"Running VAD...\")\n",
        "    model, utils = torch.hub.load(\n",
        "        repo_or_dir=\"snakers4/silero-vad\", model=\"silero_vad\", onnx=False\n",
        "    )\n",
        "\n",
        "    # required VAD utilities from silero\n",
        "    (get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n",
        "    \n",
        "    # Generate VAD timestamps\n",
        "    VAD_SR = 16000\n",
        "    wav = read_audio(f\"{VAD_temp_path}/{audio_name}\", sampling_rate=VAD_SR)\n",
        "    t = get_speech_timestamps(wav, model, sampling_rate=VAD_SR, threshold=vad_threshold)\n",
        "\n",
        "    #? Add a bit of padding, and remove small gaps\n",
        "    for i in range(len(t)):\n",
        "        t[i][\"start\"] = max(0, t[i][\"start\"] - 3200)  # 0.2s head\n",
        "        t[i][\"end\"] = min(wav.shape[0] - 16, t[i][\"end\"] + 20800)  # 1.3s tail\n",
        "        if i > 0 and t[i][\"start\"] < t[i - 1][\"end\"]:\n",
        "            t[i][\"start\"] = t[i - 1][\"end\"]  # Remove overlap\n",
        "\n",
        "    #? Inserts [] where to split audio files to multiple\n",
        "    # If breaks are longer than chunk_threshold seconds, split into a new audio file\n",
        "    # This'll effectively turn long transcriptions into many shorter ones\n",
        "    #* Metadata for chunk files\n",
        "    u = [[]] \n",
        "    for i in range(len(t)):\n",
        "        if i > 0 and t[i][\"start\"] > t[i - 1][\"end\"] + (chunk_threshold * VAD_SR):\n",
        "            u.append([])\n",
        "        u[-1].append(t[i])\n",
        "\n",
        "    #? Merge speech chunks, and delete the original\n",
        "    for i in range(len(u)):\n",
        "        save_audio(\n",
        "            f\"{VAD_temp_path}/\" + str(i) + \".wav\",\n",
        "            collect_chunks(u[i], wav),\n",
        "            sampling_rate=VAD_SR,\n",
        "        )\n",
        "    os.remove(f\"{VAD_temp_path}/{audio_name}\")\n",
        "\n",
        "    #? Convert timestamps to seconds\n",
        "    for i in range(len(u)):\n",
        "        time = 0.0\n",
        "        offset = 0.0\n",
        "        for j in range(len(u[i])):\n",
        "            u[i][j][\"start\"] /= VAD_SR\n",
        "            u[i][j][\"end\"] /= VAD_SR\n",
        "            u[i][j][\"chunk_start\"] = time\n",
        "            time += u[i][j][\"end\"] - u[i][j][\"start\"]\n",
        "            u[i][j][\"chunk_end\"] = time\n",
        "            if j == 0:\n",
        "                offset += u[i][j][\"start\"]\n",
        "            else:\n",
        "                offset += u[i][j][\"start\"] - u[i][j - 1][\"end\"]\n",
        "            u[i][j][\"offset\"] = offset\n",
        "\n",
        "    #? return the Metadata information of the chunk files\n",
        "    # Open the file in write mode.\n",
        "    with open(f\"{VAD_temp_path}/{audio_name}.json\", 'w') as json_file:\n",
        "      json.dump(u, json_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RmrRrf1mnR2R"
      },
      "outputs": [],
      "source": [
        "#The main translation function\n",
        "def run_Whisper(VAD_temp_path,model_size='large-v2',language='English',task='translate',max_attempts=1):\n",
        " \n",
        "    \n",
        "    u_path = VAD_temp_path +'/' +[pos_json for pos_json in os.listdir(VAD_temp_path) if pos_json.endswith('.json')][0]\n",
        "    with open(u_path) as json_file:\n",
        "      u = json.load(json_file)\n",
        "    #? Run Whisper on each audio chunk\n",
        "    print(\"Running Whisper...\")\n",
        "    model = whisper.load_model(model_size)\n",
        "\n",
        "    sub_index = 1\n",
        "    subs = []\n",
        "    #? the run\n",
        "    #TODO removing initial_prompt @adds extra complexity we do not need right now\n",
        "    for i in tqdm(range(len(u))):\n",
        "        \n",
        "        #? for loop for retry, incase of Hallucinations\n",
        "        # so if transcription returns empty or within constraint text break loop\n",
        "        for x in range(max_attempts):\n",
        "            result = model.transcribe(\n",
        "                f\"{VAD_temp_path}/\" + str(i) + \".wav\", task=task, language=language, #TODO removed initial_prompt=initial_prompt\n",
        "            )\n",
        "            #? Break if result doesn't end with severe hallucinations\n",
        "            if len(result[\"segments\"]) == 0:\n",
        "                break\n",
        "            elif result[\"segments\"][-1][\"end\"] < u[i][-1][\"chunk_end\"] + 10.0:\n",
        "                break\n",
        "            elif x+1 < max_attempts:\n",
        "                print(\"Retrying chunk\", i)\n",
        "        \"\"\"takes in the current Segment{result} chunk{u} and srt part{i}\"\"\"\n",
        "        \n",
        "        suppress_low = [\n",
        "            \"Thank you\",\"Thanks for\",\"ike and \",\"Bye.\",\"Bye!\",\"Bye bye!\",\"lease sub\",\"The end.\",\"視聴\",]\n",
        "        suppress_high = [\n",
        "            \"ubscribe\",\"my channel\",\"the channel\",\"our channel\",\"ollow me on\",\"for watching\",\n",
        "            \"hank you for watching\",\"for your viewing\",\"r viewing\",\"Amara\",\"next video\",\n",
        "            \"full video\",\"ranslation by\",\"ranslated by\",\"ee you next week\",\n",
        "            \"ご視聴\",\"視聴ありがとうございました\",]\n",
        "\n",
        "        #post proccessing itesm\n",
        "        for r in result[\"segments\"]:\n",
        "          # Skip audio timestamped after the chunk has ended\n",
        "          if r[\"start\"] > u[i][-1][\"chunk_end\"]:\n",
        "              continue\n",
        "\n",
        "          # Reduce log probability for certain words/phrases\n",
        "          for s in suppress_low:\n",
        "              if s in r[\"text\"]:\n",
        "                  r[\"avg_logprob\"] -= 0.15\n",
        "          for s in suppress_high:\n",
        "              if s in r[\"text\"]:\n",
        "                  r[\"avg_logprob\"] -= 0.35\n",
        "\n",
        "          # Keep segment info for debugging\n",
        "          del r[\"tokens\"]\n",
        "\n",
        "          # Skip if log prob is low or no speech prob is high\n",
        "          if r[\"avg_logprob\"] < -1.0 or r[\"no_speech_prob\"] > 0.7:\n",
        "              continue\n",
        "\n",
        "          # Set start timestamp\n",
        "          start = r[\"start\"] + u[i][0][\"offset\"]\n",
        "          for j in range(len(u[i])):\n",
        "              if (\n",
        "                  r[\"start\"] >= u[i][j][\"chunk_start\"]\n",
        "                  and r[\"start\"] <= u[i][j][\"chunk_end\"]\n",
        "              ):\n",
        "                  start = r[\"start\"] + u[i][j][\"offset\"]\n",
        "                  break\n",
        "\n",
        "          # Prevent overlapping subs\n",
        "          if len(subs) > 0:\n",
        "              last_end = subs[-1]['end']\n",
        "              if last_end > start:\n",
        "                  subs[-1]['end'] = start\n",
        "\n",
        "          # Set end timestamp\n",
        "          end = u[i][-1][\"end\"] + 0.5\n",
        "          for j in range(len(u[i])):\n",
        "              if r[\"end\"] >= u[i][j][\"chunk_start\"] and r[\"end\"] <= u[i][j][\"chunk_end\"]:\n",
        "                  end = r[\"end\"] + u[i][j][\"offset\"]\n",
        "                  break\n",
        "                  \n",
        "          # Add to SRT list\n",
        "          subs.append({\"id\":sub_index,\n",
        "                  'start':start,\n",
        "                  'end':end,\n",
        "                  'text':r[\"text\"].strip()})\n",
        "\n",
        "          sub_index = 1\n",
        "    \n",
        "    return subs\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE02PuO8xotu"
      },
      "source": [
        "###### Infrence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8eoZexTH_Jgg"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "import datetime\n",
        "import time\n",
        "from whisper.utils import get_writer\n",
        "import shutil\n",
        "\n",
        "def processor_function(input_file_path,temp_vad_path='temp'):\n",
        "    proccess_for_VAD(input_file_path,temp_vad_path)\n",
        "    subs = run_Whisper(temp_vad_path)\n",
        "    return subs,temp_vad_path\n",
        "\n",
        "def process_new_files(folder_path):\n",
        "    # create logs directory if it doesn't exist\n",
        "    # logs_dir = os.path.join(folder_path, \"logs\")\n",
        "    logs_dir ='logs'\n",
        "    os.makedirs(logs_dir, exist_ok=True)\n",
        "\n",
        "    # initialize processed files set igoring previously processed onces and non-media items\n",
        "    processed_files = set()\n",
        "    media_extensions = [\".mp3\", \".wav\", \".ogg\", \".flac\", \".m4a\", \".wma\", \".mp4\", \n",
        "                        \".mov\", \".avi\", \".mkv\", \".webm\", \".flv\", \".wmv\", \".mpeg\"]\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file_name in files:\n",
        "            if file_name.startswith(\"_done_\") or os.path.splitext(file_name)[1] not in media_extensions:\n",
        "                processed_files.add(os.path.join(root, file_name))\n",
        "\n",
        "    \n",
        "    # get list of all files in the folder\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(root, file_name)\n",
        "\n",
        "            # check if file hasn't been processed yet\n",
        "            if file_path not in processed_files:\n",
        "                # process the file\n",
        "                output,temp_vad_path = processor_function(file_path)\n",
        "\n",
        "                # create log file with date and time stamp, and maintain folder structure\n",
        "                \n",
        "                # temp_name = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") +'.log'\n",
        "                log_file_name = file_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") \n",
        "                log_file_path = os.path.join(logs_dir, os.path.relpath(file_path, folder_path)).replace(file_name, log_file_name+ \"/\")\n",
        "                os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
        "\n",
        "                # write all the results in our structured file format\n",
        "                writer = get_writer('all', log_file_path)\n",
        "                writer({\"segments\":output}, os.path.splitext(file_name)[0])\n",
        "                shutil.rmtree(temp_vad_path)\n",
        "\n",
        "                # rename the file with '_done_' prefix\n",
        "                done_file_path = os.path.join(root, \"_done_\" + file_name)\n",
        "                os.rename(file_path, done_file_path)\n",
        "\n",
        "                # add the file to the processed files set\n",
        "                processed_files.add(done_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUA4zT40rY-p"
      },
      "source": [
        "###### Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "flLZSeiDlsCi"
      },
      "outputs": [],
      "source": [
        "process_new_files(\"in_folder\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SnW7Gf5brhVb",
        "eE02PuO8xotu",
        "kUA4zT40rY-p"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
